# BIGDATA_PROJECT - Há»‡ thá»‘ng xá»­ lÃ½ dá»¯ liá»‡u báº¥t Ä‘á»™ng sáº£n Real-time

Dá»± Ã¡n xÃ¢y dá»±ng pipeline Big Data thu tháº­p vÃ  xá»­ lÃ½ dá»¯ liá»‡u báº¥t Ä‘á»™ng sáº£n tá»« nhatot.com.

## ğŸ“ Kiáº¿n trÃºc há»‡ thá»‘ng

```
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   Data Source      â”‚
           â”‚ nhatot.com Web     â”‚
           â”‚ Scraping/ Crawlingâ”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”
           â”‚ Data Ingestion     â”‚
           â”‚ (Kafka Producer)   â”‚
           â”‚ Stream of Listings â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ Stream Processing â”‚ 
           â”‚ (Apache Spark     â”‚
           â”‚ Structured Streaming) â”‚
           â”‚ - Clean data      â”‚
           â”‚ - Transformations â”‚
           â”‚ - UDFs, Aggregatesâ”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                          â”‚
        â–¼                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Batch Storage     â”‚       â”‚ NoSQL Database    â”‚
â”‚ HDFS              â”‚       â”‚ MongoDB           â”‚
â”‚ Raw & Processed   â”‚       â”‚ Fast querying &   â”‚
â”‚ Data              â”‚       â”‚ analytics         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                          â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ Visualization â”‚
               â”‚ Dashboards    â”‚
               â”‚ (Grafana /    â”‚
               â”‚ Superset)     â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Cáº¥u trÃºc Project

```
BIGDATA_PROJECT/
â”œâ”€â”€ CrawlData.py              # Module crawl dá»¯ liá»‡u tá»« nhatot.com API
â”œâ”€â”€ kafka_producer.py         # Kafka Producer - stream data vÃ o Kafka âœ…
â”œâ”€â”€ kafka_consumer_test.py    # Test consumer Ä‘á»ƒ kiá»ƒm tra data trong Kafka
â”œâ”€â”€ test_spark_streaming.py   # [Cáº¦N TRIá»‚N KHAI] Spark Structured Streaming
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ data_input/house/         # Dá»¯ liá»‡u Ä‘Ã£ crawl (backup)
â”‚   â””â”€â”€ 2025-12-12/          # 36+ JSON files
â””â”€â”€ README.md                 # File nÃ y
```

## ğŸ”§ MÃ´i trÆ°á»ng cáº§n thiáº¿t

### ÄÃ£ cÃ i Ä‘áº·t trÃªn WSL2:
- **Java 11** (`/usr/lib/jvm/java-11-openjdk-amd64`)
- **Kafka 3.6.1** (`/usr/local/kafka`)
- **Hadoop** (`/usr/local/hadoop`)
- **Spark** - Cáº§n cÃ i Ä‘áº·t cho Stream Processing

### Python Libraries:
```bash
pip install -r requirements.txt
# CÃ i Ä‘áº·t: requests, kafka-python, python-dotenv
```

---

##  Cáº¥u hÃ¬nh mÃ´i trÆ°á»ng (.env)

### BÆ°á»›c 1: Táº¡o file .env
```bash
# Copy file template
cp .env.example .env
```

### BÆ°á»›c 2: Láº¥y IP cá»§a WSL2
Trong WSL2 terminal, cháº¡y:
```bash
hostname -I
# VÃ­ dá»¥ káº¿t quáº£: 172.27.34.172
```

### BÆ°á»›c 3: Cáº­p nháº­t file .env

Ná»™i dung file `.env`:
```env
# IP cá»§a WSL2 (thay báº±ng IP thá»±c táº¿ cá»§a báº¡n)
WSL2_IP=172.27.34.172

# Kafka Configuration
KAFKA_PORT=9092
KAFKA_TOPIC=house-listings

# Producer Settings
CRAWL_LIMIT=50
BATCH_SIZE=10
```

**LÆ°u Ã½:** 
- Má»—i khi restart Windows, IP cá»§a WSL2 cÃ³ thá»ƒ thay Ä‘á»•i, cáº§n cáº­p nháº­t láº¡i

---

## Pháº§n 1: DATA INGESTION

### Khá»Ÿi Ä‘á»™ng Kafka Cluster

#### Terminal WSL 1 - Zookeeper:
```bash
cd /usr/local/kafka
bin/zookeeper-server-start.sh config/zookeeper.properties
```

#### Terminal WSL 2 - Kafka:
```bash
cd /usr/local/kafka
bin/kafka-server-start.sh config/server.properties
```

#### Kiá»ƒm tra services:
```bash
jps
# Pháº£i tháº¥y:
# XXXX QuorumPeerMain (Zookeeper)
# YYYY Kafka
```

### Táº¡o Kafka Topic

```bash
kafka-topics.sh --create --topic house-listings \
  --bootstrap-server localhost:9092 \
  --partitions 3 \
  --replication-factor 1

# Kiá»ƒm tra topic
kafka-topics.sh --list --bootstrap-server localhost:9092
kafka-topics.sh --describe --topic house-listings --bootstrap-server localhost:9092
```

###  Cháº¡y Producer (tá»« Windows)

#### BÆ°á»›c 1: CÃ i Ä‘áº·t dependencies
```bash
pip install -r requirements.txt
```

#### BÆ°á»›c 2: Äáº£m báº£o file .env Ä‘Ã£ cáº¥u hÃ¬nh Ä‘Ãºng
```bash
# Kiá»ƒm tra file .env cÃ³ WSL2_IP Ä‘Ãºng khÃ´ng
cat .env  # WSL2
# hoáº·c
type .env  # Windows CMD
# hoáº·c
Get-Content .env  # PowerShell
```

#### BÆ°á»›c 3: Cháº¡y Producer
```bash
python kafka_producer.py
```

**Káº¿t quáº£ mong Ä‘á»£i:**
```
[CONFIG] Kafka Bootstrap: 172.27.34.172:9092
[CONFIG] Topic: house-listings
[CONFIG] Crawl Limit: 50, Batch Size: 10
[âœ“] Kafka connection successful!
[INFO] Kafka Producer initialized - Topic: house-listings
[INFO] Starting to crawl and stream 50 listings...
[INFO] Láº¥y Ä‘Æ°á»£c 50 list_id.
[1/50] Processing ID: 129940480
[SUCCESS] Sent ID: 129940480 â†’ Topic: house-listings, Partition: 0, Offset: 0
...
[COMPLETED] Sent 50/50 listings to Kafka
```

**Náº¿u lá»—i káº¿t ná»‘i:**
- Kiá»ƒm tra Kafka Ä‘ang cháº¡y: `jps` trong WSL2
- Cáº­p nháº­t láº¡i `WSL2_IP` trong file `.env`
- Test connection: `Test-NetConnection -ComputerName <WSL2_IP> -Port 9092`

### Kiá»ƒm tra dá»¯ liá»‡u trong Kafka

#### Tá»« WSL2:
```bash
# Xem 5 messages Ä‘áº§u
kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic house-listings \
  --from-beginning \
  --max-messages 5
```

#### Tá»« Windows:
```bash
python kafka_consumer_test.py
```

### Format dá»¯ liá»‡u trong Kafka

Má»—i message cÃ³ format JSON:
```json
{
  "id": 129940480,
  "title": "BÃ¡n cÄƒn há»™ 2PN...",
  "description": "...",
  "price": 3650000000,
  "area_m2": 123,
  "price_per_m2": 29674796.75,
  "region": "HÃ  Ná»™i",
  "district": "Huyá»‡n Gia LÃ¢m",
  "ward": "Thá»‹ tráº¥n TrÃ¢u Quá»³",
  "street": "YÃªn ViÃªn",
  "lat": 21.02097,
  "lng": 105.93817,
  "property_type": null,
  "category": 1010,
  "post_time": 1765506961000,
  "images": 12,
  "crawl_timestamp": 1735306123.456,
  "source": "nhatot.com"
}
```
